\section{Generación de clasificadores y entrenamiento}

\paragraph{} Se implementó un componente de software dedicado a crear, entrenar y persistir clasificadores de aprendizaje automático. Este componente de software permite seleccionar como clasificador de aprendizaje automático a utilizar \textit{SVM} o redes neuronales.

\paragraph{} Se utiliza la librería \textit{Pandas}\citet{bib-pandas} de \textit{Python}, que simplifica el manejo de los datos mediante estructuras de datos indizadas y con un conjunto de métodos que permiten realizar operaciones sobre éstas estructuras para facilitar el análisis de los datos, haciendo un uso eficiente de los recursos de la máquina.

\paragraph{} En base a Dorronsoro et al. (2013), se utilizó cada fila de la matriz ETC del problema como ejemplos de entrenamiento, es decir, para una matriz de $512$ tareas y $16$ máquinas, se obtendrán $512$ ejemplos de entrenamiento, cada uno clasificado en una de las $16$ clases objetivo. Estas clases corresponden una a una con las máquinas asignadas por el algoritmo $Min-Min$. La figura \ref{table:datosentrenamiento} muestra un ejemplo de matriz ETC de $512$ tareas y $16$ máquinas, cada tarea con su máquina asignada siendo esta asignación el atributo objetivo.

\begin{figure}[ht!]
\[
\begin{bmatrix}
     & m_1 & m_2 & \dots  & m_{16} & objetivo \\
    t_1 & 35.74 & 39.62 & \dots  & 456.89 & 4 \\
    t_2 & 75.55 & 97.41a & \dots  & 579.19 & 3 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
    t_{512} & 130.12 & 216.59 & \dots  & 789.84 & 5\\
\end{bmatrix}
\]
\caption{Ejemplo de matriz ETC con atributo objetivo para el aprendizaje. Cada $t_i$ con $i = 1 \dots 512$ es información correspondiente a una tarea. Esta información equivale a un ejemplo de entrenamiento para el clasificador. La columna objetivo muestra la asignación de máquina para la correspondiente tarea $i$ y éste es el atributo objetivo para los clasificadores.}
\label{table:datosentrenamiento}
\end{figure}

A diferencia de utilizar la matriz ETC completa como ejemplo de entrenamiento, utilizar cada fila de la matriz se traduce en menores tiempos de entrenamiento y además da flexibilidad a la hora de clasificar problemas con otro número de tareas e igual número de máquinas. Esto es, como los clasificadores se entrenan con información referente a cada tarea, se pueden clasificar problemas que tengan número menor o mayor de tareas. 

\paragraph{} Para el entrenamiento se utilizaron $100$ instancias del problema de dimensión $512 \times 16$, lo que se traduce en $51200$ instancias de entrenamiento cada una asignada a un atributo objetivo que varía de $1$ a $16$. El componente de software implementado carga a memoria 100 archivos $csv$ que se encuentran en un directorio definido, donde cada archivo es una matriz ETC con el atributo objetivo correspondiente, como se muestra en la figura \ref{table:datosentrenamiento}, los cuales se agregan en un solo \textit{DataFrame}\cite{DataFrame-pandas} de \textit{Pandas}. Este \textit{DataFrame} es escalado y utilizado para el entrenamiento de los clasificadores.

\paragraph{} Debido a que los datos contienen atributos cuyas magnitudes tienen una gran varianza y los algoritmos utilizados manejan distancias euclideanas para el aprendizaje, los datos se escalaron antes de realizar el entrenamiento de los clasificadores. Otra razón para esclar los datos antes del entrenamiento es que \textit{Gradiente Descendente} converge más rápido cuando los datos están escalados\cite{gradiente-descendente-escalado}.

\paragraph{} El escalado de los datos se realiza mediante la clase $preprocessing.StandardScaler()$ de la librería \textit{Scikit-Learn} para \textit{Python} \cite{scikit-learn}. Ésta librería provee el soporte para los métodos de aprendizaje automático y herramientas para el preprocesamiento de los datos. En particular la clase $StandardScaler()$ analizará cada atributo de manera independiente y almacenará la mediana y la desviación estándar para luego ser utilizados en datos nuevos que ingresen al modelo.\cite{StandardScaler-scikit-learn}  

\paragraph{} Para la construcción de los modelos se utilizaron las clases \textit{svm.SVC} para la construcción de los clasificadores \textit{SVM} y \textit{neural\_network.MLPClassifier} para la construcción de las redes neuronales, ambas clases pertenecientes a la librería \textit{Scikit-Learn} de \textit{Python}.

\paragraph{} Con respecto al clasificador \textit{SVM}, el mismo se utilizó siguiendo la estrategia \textit{OVR}, dado que genera menos clasificadores y además, dada la baja heterogeneidad de las instancias del problema, no se espera tener un desvalance en la cantidad de representantes de cada clase. 

\paragraph{} Con respecto a las redes neuronales, en particular sobre la arquitectura de las mismas se siguió la heurística recomendada por Lane (2017), dada la falta de consenso existente con respecto a la manera óptima de determinar la cantidad de neuronas en las capas ocultas de una red neuronal de acuerdo a los casos de uso en los que se apliquen dichos clasificadores. Según esta heurística, la cantidad de neuronas en una capa oculta (o $N_h$) se determina con la siguiente fórmula $N_h = \frac{N_s} {(\alpha * (N_i + N_o))}$, siendo:
\\
\\
$N_i$ = cantidad de neuronas de entrada
\\
\\
$N_o$ = cantidad de neuronas de salida
\\
\\
$N_s$ = cantidad de instancias de entrenamiento
\\
\\
$\alpha$ = factor de escalamiento arbitrario, con valor igual a 2 para este estudio

\paragraph{} HASTA ACÄ LLEGUË HOY, SIGO MAÑANA O ESTA NOCHE. DE ACA PARA ABAJO NO TIENE SENTIDO...

\paragraph{} Para esto, es utilizado un clasificador de tipo \textit{pipeline}, ofrecido por la librería \textit{scikit-learn}. Este componente de software permite que sean aplicadas una serie de transformaciones a los datos de manera previa a ser utilizados por el clasificador. A su vez, el clasificador puede mantener la configuración que el usuario prefiera, tomando información de la arquitectura deseada para una red neuronal o parámetros de inicialización en caso de optar por utilizar una SVM. 


\paragraph{} Para encontrar los mejores parámetros para comenzar con las pruebas, fue utilizado \textit{model\_selection.GridSearchCV} que permite seleccionar los mejores parámetros para entrenar un modelo. 

\paragraph{} Finalmente, este componente se encarga de persistir los clasificadores generados, proveyendo una interfaz al usuario para realizar todo lo mencionado de manera automática dado un conjunto de ejemplos de entrenamiento.

