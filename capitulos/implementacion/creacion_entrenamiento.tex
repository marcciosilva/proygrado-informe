\section{Generación de clasificadores y entrenamiento} \label{chapter-implementacion:clasificadores}

\paragraph{} Se implementó un componente de software dedicado a crear, entrenar y persistir clasificadores de aprendizaje automático.
Este componente permite seleccionar como clasificador de aprendizaje automático a utilizar \textit{SVM} o redes neuronales.

\paragraph{} Se utilizó la biblioteca \textit{Pandas}\cite{bib-pandas} de \textit{Python}.
Esta biblioteca simplifica el manejo de datos mediante estructuras de datos indizadas, proporcionando un conjunto de métodos que permiten realizar operaciones sobre estas estructuras para facilitar el análisis de los datos, haciendo un uso eficiente de los recursos computacionales sobre los que se ejecute.

\paragraph{} Como se mencionó en la sección \ref{chapter-implementacion:data}, se utilizó cada fila de la matriz ETC del problema como los atributos para un único ejemplo de entrenamiento.
Esto quiere decir que para una matriz de $512$ tareas y $16$ máquinas se obtienen $512$ ejemplos de entrenamiento, cada uno clasificado en una de las $16$ clases objetivo.
Estas clases se corresponden una a una con las máquinas asignadas por el algoritmo Min-Min.
La figura \ref{table:datosentrenamiento} muestra un ejemplo de matriz ETC de $512$ tareas y $16$ máquinas.

\begin{figure}[ht!]
\[
\begin{bmatrix}
     & m_1 & m_2 & \dots  & m_{16} & objetivo \\
    t_1 & 35.74 & 39.62 & \dots  & 456.89 & 4 \\
    t_2 & 75.55 & 97.41 & \dots  & 579.19 & 3 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
    t_{512} & 130.12 & 216.59 & \dots  & 789.84 & 5\\
\end{bmatrix}
\]
\caption{Ejemplo de matriz ETC con atributo objetivo para el aprendizaje.
Cada fila $t_i$ con $i = 1 \dots 512$ incluye información correspondiente a una tarea.
La columna objetivo muestra la asignación de máquina para la correspondiente tarea $i$ y éste es el atributo objetivo para los clasificadores.
La información asociada a la tarea, que incluye los tiempos de ejecución estimados de la tarea $t_i$ para cada una de las máquinas disponibles, junto con su clasificación, equivale a un ejemplo de entrenamiento para el clasificador.}
\label{table:datosentrenamiento}
\end{figure}

\newpage % orphaned line.

\paragraph{}A diferencia de utilizar la matriz ETC completa como ejemplo de entrenamiento, utilizar cada fila de la matriz se traducirá en menores tiempos de entrenamiento y además da flexibilidad a la hora de clasificar problemas con otro número de tareas e igual número de máquinas.
Esto es, como los clasificadores se entrenan con información referente a cada tarea, se pueden clasificar problemas que tengan un número menor o mayor de tareas.
Este tipo de escalado en función de tareas es además realista, ya que en la práctica el hardware tiende a ser una restricción menos flexible que la cantidad de tareas, algo que puede fluctuar con mayor frecuencia en función del tiempo dependiendo del caso de estudio.

\paragraph{} Para el entrenamiento se utilizaron $100$ instancias del problema de dimensión $512 \times 16$, lo que se traduce en $51200$ instancias de entrenamiento, cada una con un atributo objetivo que varía entre $1$ a $16$, siendo éste el identificador de la máquina la cual la tarea es asignada.
El componente de software implementado carga en memoria 100 archivos CSV que se encuentran en un directorio definido.
Cada uno de estos archivos es una matriz ETC con el atributo objetivo correspondiente asignado para cada tarea, como se muestra en la figura \ref{table:datosentrenamiento}.
Estos atributos objetivo se agregan en un sólo \textit{DataFrame} de \textit{Pandas} \cite{DataFrame-pandas}.
Este \textit{DataFrame} es escalado y utilizado para el entrenamiento de los clasificadores.

\paragraph{} Debido a que los datos contienen atributos cuyas magnitudes tienen una gran varianza y los algoritmos utilizados manejan distancias euclidianas para el aprendizaje, los datos fueron escalados antes de realizarse el entrenamiento de los clasificadores.
Otra razón para escalar los datos antes del entrenamiento es que \textit{Gradiente Descendente} tiende a converger más rápido cuando los datos están escalados \cite{gradiente-descendente-escalado}.

\paragraph{} El escalado de los datos se realiza mediante la clase \textit{preprocessing.StandardScaler} de la biblioteca \textit{Scikit-Learn} para \textit{Python} \cite{scikit-learn}.
Esta biblioteca provee el soporte para los métodos de aprendizaje automático y herramientas para el preprocesamiento de los datos.
En particular la clase \textit{StandardScaler} analiza cada atributo de manera independiente y almacena la mediana y la desviación estándar para luego ser utilizados en datos nuevos que ingresan al modelo \cite{StandardScaler-scikit-learn}.

\paragraph{} Para la construcción de los clasificadores de aprendizaje automático se utilizaron las clases \textit{svm.SVC} para la construcción de \textit{SVM} y \textit{neural\_network.MLPClassifier} para la construcción de las redes neuronales, ambas clases pertenecientes a la biblioteca \textit{Scikit-Learn} de \textit{Python}.

\paragraph{} El clasificador \textit{SVM} se utilizó siguiendo la estrategia \textit{OVR}, dado que genera menos clasificadores que mediante la estrategia \textit{OVO} de acuerdo a lo expuesto en la sección \ref{capitulo:svm}.
Además, se entendió a \textit{OVR} como la mejor estrategia dada la baja heterogeneidad de las instancias del problema, por lo cual es razonable no tener un desbalance en la cantidad de representantes de cada clase.

\paragraph{} Con respecto a las redes neuronales, en particular sobre su arquitectura, se siguió la heurística recomendada por \citet{bib-heuristic-hobs}, dada la falta de consenso existente en la comunidad con respecto a la manera óptima de determinar la cantidad de neuronas en las capas ocultas de una red neuronal de acuerdo a los casos de uso en los que se apliquen dichos clasificadores.
Según esta heurística, la cantidad de neuronas en una capa oculta (o $N_h$) se determina con la siguiente fórmula $N_h = \frac{N_s} {(\alpha * (N_i + N_o))}$, siendo:
\\
\\
$N_i$ = cantidad de neuronas de entrada
\\
\\
$N_o$ = cantidad de neuronas de salida
\\
\\
$N_s$ = cantidad de instancias de entrenamiento
\\
\\
$\alpha$ = factor de escalamiento arbitrario, con valor igual a 2 para este estudio

\paragraph{} El resto de los parámetros iniciales de configuración de la red neuronal se definieron utilizando la clase \textit{model\_selection.GridSearchCV}, que realiza una búsqueda exhaustiva de los mejores parámetros para el modelo mediante validación cruzada.
A medida que se avanzó con el trabajo, estos parámetros fueron modificados para ajustarlos a las necesidades puntuales del proyecto.
El detalle de los parámetros iniciales seleccionados se encuentra en la sección \ref{capitulo:configuracion}.
% TODO ¿agregar info sobre el clasificador usado para redes neuronales (MLPClassifier)?

% TODO la ref Pipeline-scikit-learn no figura en bibliography.bib
\paragraph{} A un nivel de abstracción superior, tanto para SVM como para redes neuronales, se utilizó la clase \textit{pipeline.Pipeline} de la biblioteca \textit{Scikit-Learn}.
Esta clase envuelve al clasificador escogido, y permite que los datos fluyan desde su forma original, pasando secuencialmente por cada etapa del preprocesamiento, para finalmente ingresar en el clasificador.
La utilización de esta clase permite la evaluación del modelo con estrategias como validación cruzada, simplificando la implementación del preprocesamiento de los datos mediante una encadenación de transformaciones atómicas.
En particular, se utilizó la clase \textit{Pipeline} con el escalado encadenado al clasificador seleccionado. 

\paragraph{} Para realizar el entrenamiento de los clasificadores se utilizaron los servicios de máquinas virtuales EC2 de Amazon Web Services \cite{aws}.
Este servicio permite escalar de forma sencilla los recursos computacionales.
En particular se generó una máquina virtual con 2 CPUs virtuales cada uno de 2.5GHz, y 16GB de RAM.
El uso de estos recursos permitió realizar el entrenamiento de los clasificadores en un ambiente aislado y seguro para prevenir fallas por utilizar ambientes locales. 

\paragraph{} Finalmente, el componente de software desarrollado se encarga de persistir los clasificadores generados.
Para esto se utiliza la clase \textit{externals.Joblib} de \textit{Scikit-Learn}.
El uso de \textit{Joblib} es sugerido cuando se utilizan clasificadores de \textit{Scikit-Learn}, dado que provee una manera eficiente de almacenar objetos que contienen gran cantidad de \textit{arrays} de \textit{numpy} \cite{numpy}, que es el caso de modelos de \textit{Scikit-Learn} ya entrenados \cite{persistence}.
Esta biblioteca no solo permite llevar a cabo la persistencia de los modelos sino que también permite la carga en memoria de los modelos para su utilización.

