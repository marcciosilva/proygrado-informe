\section{Generación de clasificadores y entrenamiento}

\paragraph{} Se implementó un componente de software dedicado a crear, entrenar y persistir clasificadores de aprendizaje automático. Este componente de software permite seleccionar como clasificador de aprendizaje automático a utilizar \textit{SVM} o redes neuronales.

\paragraph{} Se utiliza la librería \textit{Pandas}\citet{bib-pandas} de \textit{Python}, que simplifica el manejo de los datos mediante estructuras de datos indizadas y con un conjunto de métodos que permiten realizar operaciones sobre éstas estructuras para facilitar el análisis de los datos, haciendo un uso eficiente de los recursos de la máquina.

\paragraph{} En base a Dorronsoro et al. (2013), se utilizó cada fila de la matriz ETC del problema como ejemplos de entrenamiento, es decir, para una matriz de $512$ tareas y $16$ máquinas, se obtendrán $512$ ejemplos de entrenamiento, cada uno clasificado en una de las $16$ clases objetivo. Estas clases corresponden una a una con las máquinas asignadas por el algoritmo $Min-Min$. La figura \ref{table:datosentrenamiento} muestra un ejemplo de matriz ETC de $512$ tareas y $16$ máquinas, cada tarea con su máquina asignada siendo esta asignación el atributo objetivo.


\begin{figure}[ht!]
\[
\begin{bmatrix}
     & m_1 & m_2 & \dots  & m_{16} & objetivo \\
    t_1 & 35.74 & 39.62 & \dots  & 456.89 & 4 \\
    t_2 & 75.55 & 97.41a & \dots  & 579.19 & 3 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
    t_{512} & 130.12 & 216.59 & \dots  & 789.84 & 5\\
\end{bmatrix}
\]
\caption{Ejemplo de matriz ETC con atributo objetivo para el aprendizaje. Cada $t_i$ con $i = 1 \dots 512$ es información correspondiente a una tarea. Esta información equivale a un ejemplo de entrenamiento para el clasificador. La columna objetivo muestra la asignación de máquina para la correspondiente tarea $i$ y éste es el atributo objetivo para los clasificadores.}
\label{table:datosentrenamiento}
\end{figure}

A diferencia de utilizar la matriz ETC completa como ejemplo de entrenamiento, utilizar cada fila de la matriz se traduce en menores tiempos de entrenamiento y además da flexibilidad a la hora de clasificar problemas con otro número de tareas e igual número de máquinas. Esto es, como los clasificadores se entrenan con información referente a cada tarea, se pueden clasificar problemas que tengan número menor o mayor de tareas. 

\paragraph{} Para el entrenamiento se utilizaron $100$ instancias del problema de dimensión $512 \times 16$, lo que se traduce en $51200$ instancias de entrenamiento cada una asignada a un atributo objetivo que varía de $1$ a $16$. El componente de software implementado carga a memoria 100 archivos $csv$ que se encuentran en un directorio definido, donde cada archivo es una matriz ETC con el atributo objetivo correspondiente, como se muestra en la figura \ref{table:datosentrenamiento}, los cuales se agregan en un solo \textit{DataFrame}\cite{DataFrame-pandas} de \textit{Pandas}. Este \textit{DataFrame} es escalado y utilizado para el entrenamiento de los clasificadores.

\paragraph{} Debido a que los datos contienen atributos cuyas magnitudes tienen una gran varianza y los algoritmos utilizados manejan distancias euclideanas para el aprendizaje, los datos se escalaron antes de realizar el entrenamiento de los clasificadores. Otra razón para esclar los datos antes del entrenamiento es que \textit{Gradiente Descendente} converge más rápido cuando los datos están escalados\cite{gradiente-descendente-escalado}.

\paragraph{} El escalado de los datos se realiza mediante la clase $preprocessing.StandardScaler()$ de la librería \textit{Scikit-Learn} para \textit{Python} \cite{scikit-learn}. Ésta librería provee el soporte para los métodos de aprendizaje automático y herramientas para el preprocesamiento de los datos. En particular la clase $StandardScaler()$ analizará cada atributo de manera independiente y almacenará la mediana y la desviación estándar para luego ser utilizados en datos nuevos que ingresen al modelo.\cite{StandardScaler-scikit-learn}  

\paragraph{} Para la construcción de los modelos se utilizaron las clases \textit{svm.SVC} para la construcción de los clasificadores \textit{SVM} y \textit{neural\_network.MLPClassifier} para la construcción de las redes neuronales, ambas clases pertenecientes a la librería \textit{Scikit-Learn} de \textit{Python}.

\paragraph{} Con respecto al clasificador \textit{SVM}, el mismo se utilizó siguiendo la estrategia \textit{OVR}, dado que genera menos clasificadores que mediante la estrategia \textit{OVO} y además, dada la baja heterogeneidad de las instancias del problema, no se espera tener un desvalance en la cantidad de representantes de cada clase.

\paragraph{} Con respecto a las redes neuronales, en particular sobre la arquitectura de las mismas, se siguió la heurística recomendada por \citet{bib-heuristic-hobs}, dada la falta de consenso existente con respecto a la manera óptima de determinar la cantidad de neuronas en las capas ocultas de una red neuronal de acuerdo a los casos de uso en los que se apliquen dichos clasificadores. Según esta heurística, la cantidad de neuronas en una capa oculta (o $N_h$) se determina con la siguiente fórmula $N_h = \frac{N_s} {(\alpha * (N_i + N_o))}$, siendo:
\\
\\
$N_i$ = cantidad de neuronas de entrada
\\
\\
$N_o$ = cantidad de neuronas de salida
\\
\\
$N_s$ = cantidad de instancias de entrenamiento
\\
\\
$\alpha$ = factor de escalamiento arbitrario, con valor igual a 2 para este estudio

\paragraph{} El resto de los parámetros iniciales de configuración de la red neuronal se definieron mediante la clase \textit{model\_selection.GridSearchCV}, que realiza una busqueda exaustiva de los mejores parámetros para el modelo mediante validación cruzada. A medida que se avanzó con el trabajo, estos parámetros fueron modificados para ajustarlos a las necesidades puntuales del proyecto. El detalle de los parámetros iniciales selectos se encuentra en la sección \ref{capitulo:configuracion}.

\paragraph{} Se utilizó un clasificador de la clase \textit{pipeline.Pipeline}\cite{Pipeline-scikit-learn} de la libreía \textit{Scikit-Learn}, este tipo de clasificadores permite que los datos fluyan desde su forma en bruto, pasando secuencialmente por cada etapa del preprocesamiento, para finalmente ingresar en el clasificador elegido (\textit{SVM} o redes neuronales), permitiendo la evaluación del modelo con estrategias como valización cruzada, simplificando la implementación del preprocesamiento de los datos mediante una encadenación de transformaciones. En particular, se utilizó un \textit{Pipeline} con el escalado encadenado al clasificador seleccionado. 

\paragraph{} Finalmente, el componente de software desarrollado se encarga de persistir los clasificadores generados. Para esto se utiliza la clase \textit{externals.Joblib} de \textit{Scikit-Learn}. El uso de \textit{Joblib} es sugerido cuando se utilizan clasificadores de \textit{Scikit-Learn}, dado que \textit{Joblib} provee una manera eficiente de almacenar objetos que contienen gran cantidad de \textit{arrays} de \textit{numpy}\cite{numpy}, que es el caso de modelos de \textit{Scikit-Learn} ya entrenados.\cite{persistence}. Esta librería no solo permite la persistencia de los modelos sino que también permite la carga de los mismos a memoria para su utilización.

